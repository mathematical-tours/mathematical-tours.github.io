% !TEX root = ../FundationsDataScience.tex

\chapter{Wavelets}

The reference for this chapter is \cite{mallat2008wavelet}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Multi-resolution Approximation Spaces}

A multiresolution approximation of $L^2(\RR)$ is a set of nested closed subspaces $(V_j)_j$ 
\eql{\label{eq-nested-spaces}
	L^2(\RR) \supset \ldots \supset V^{j-1} \supset V_j \supset V_{j+1} \supset \ldots \supset \{0\}
}
which must be related one from each other by dyadic scaling and must also be stable by dyadic translation 
\eq{
	f \in V_j \quad\Longleftrightarrow\quad f(\cdot/2) \in V_{j+1}
	\qandq
	f \in V_j \quad\Longleftrightarrow\quad \foralls n \in \ZZ, \: f(\cdot+t2^j) \in V_{j}
}
So large $j$ corresponds to coarse approximation spaces, and $2^j$ is often call the ``scale''.

The limit on the left of~\eqref{eq-nested-spaces} means that $\cup_j V_j$ is dense in $L^2(\RR)$, or equivalently that $P_{V_j}(f) \rightarrow f$ as $j \rightarrow -\infty$ where $P_V$ is the orthogonal projector on $V$
\eq{
	P_V(f) = \uargmin{f' \in V} \norm{f-f'}.
}
The limit on the right of~\eqref{eq-nested-spaces} means that $\cap_j V_j = \{0\}$, or equivalently that $P_{V_j}(f) \rightarrow 0$ as $j \rightarrow +\infty$.

%%
\paragraph{Scaling functions.}

We also require that there exists a scaling function $\phi \in L^2(\RR)$ so that  
\eq{
	\{ \phi(\cdot-n) \}_n \text{ is an Hilertian orthonormal basis of } V_0.
}
By the dilation property, this implies that 
\eq{
	\{ \phi_{j,n} \}_n \text{ is an Hilertian orthonormal basis of } V_j
	\qwhereq
	\phi_{j,n} \eqdef \frac{1}{2^{j/2}} \phi\pa{ \frac{\cdot - 2^j n}{2^j} }.
}
Note that one then has
\eq{
	P_{V_j}(f) = \sum_n \dotp{f}{\phi_{j,n}} \phi_{j,n}. 
}
Figure~\ref{fig-multires-1d} illustrates the translation and scaling effect. 


\myfigure{
\tabtrois{
\image{wavelets}{.3}{multires-1d-1}&
\image{wavelets}{.3}{multires-1d-2}&
\image{wavelets}{.3}{multires-1d-3}\\
$\phi_{j,0}$ & $\phi_{j+1,2}$ & $\phi_{j-1,}$
}
}{%
	Translation and scaling to generate approximation spaces.%	
}{fig-multires-1d}


A typical example is approximation by piecewise constant signals
\eql{\label{eq-haar-multires}
	V_j \eqdef \enscond{f \in L^2(\RR)}{\forall n, f \text{ is constant on } [2^j n, 2^j (n+1)[}, 
}
in which case one can use $\phi = 1_{[0,1[}$ and $\phi_{j,n} = 2^{-j/2}1_{[2^j n, 2^j (n+1)[}$ .

\myfigure{
\image{wavelets}{.3}{multires-1d-haar-wavelet}
\image{wavelets}{.3}{multires-1d-haar-scaling}
}{%
	Haar scaling (left) and wavelet (right) functions.%	
}{fig-haard-scaling-wav} 

%%
\paragraph{Spectral orthogonalization.}

In many case of practical interest, the space $V_j$ is describe by a translation-invariant basis which is not-orthogonal, $V_j=\Span(\th(\cdot-n))_{n \in \ZZ}$. The following proposition shows how to orthogonalize it using the Fourier transform.

\begin{prop}\label{prop-spectral-ortho}
	For $\th \in L^2(\RR)$ (assumed regular and with fast enough decay), $\{\th(\cdot-n)\}_{n \in \ZZ}$ is orthonormal if and only if
	\eq{
		\foralls \om, \quad A(\om) \eqdef \sum_{k} |\hat \th(\om-2\pi k)|^2 = 1.
	}
	If there exists $0 < a \leq b <+\infty$ such that $a \leq A(\om) \leq b$, then $\phi$ defined by
	\eq{
		\hat\phi(\om) = \frac{\hat\th(\om)}{\sqrt{A(\om)}}
	}
	is such that $\{\phi(\cdot-n)\}_{n \in \ZZ}$ is an Hilbertian basis of $\Span\{\th(\cdot-n)\}_{n \in \ZZ}$.
\end{prop}

\begin{proof}
	One has that $\{\th(\cdot-n)\}_{n \in \ZZ}$ is orthonormal if and only if 
	\eq{
		\dotp{\th}{\th(\cdot-n)} = (\th \star \bar\th)(n) = \de_{0,n} \eqdef
		\choice{
			0 \qifq n=0, \\
			1 \quad\text{otherwise.}
		}
	}
	where $\bar\th=\th(?\cdot)$ and $\de_0$ is the discrete Dirac vector. 
	%
	The Poisson summation formula~\eqref{eq-poisson-formula} then reads
	\eq{
		\sum_n \Ff(\th \star \bar\th)(\om-2\pi n) = \sum_n  \de_{0,n} e^{-\imath \om} = 1.
	}
	We conclude with the Fourier-convolution formula~\eqref{eq-convol-fourier} shows that $\Ff(\th \star \bar\th)(\om)=\hat\th(\om)\hat\th(\om)^*=|\hat\th(\om)|^2$ which leads to the desired formula, and it is if and only if. 
	%
	Normalizing by $1/\sqrt{A(\om)}$, which is a bounded function, shows that $\hat\phi$ satsifies $\sum_{k} |\hat \phi(\om-2\pi k)|^2 = 1$.
\end{proof}

A typical example of application is spline (e.g. cubic ones) interpolations, which are generated by the box-spline function $\th$ which is a piecewise polynomial with a compact support. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Multi-resolution Details Spaces}

The details spaces are defined as orthogonal complement of $V_j \subset V_{j-1}$, which is legit because these are closed subspaces
\eq{
	\foralls j, \quad W_j \text{ is such that } V_{j-1} = V_j \oplus^\bot W_j. 
}
This leads to the following sequence of embedded spaces
\begin{center}
	\image{wavelets}{.8}{embeded-spaces-1d}
\end{center}
Once again, we suppose that $W_0$ has an Hilbertian ortho-basis of the form $\{\psi(\cdot-n)\}_n$, so that 
\eq{
	\{ \psi_{j,n} \}_n \text{ is an Hilertian orthonormal basis of } V_j
	\qwhereq
	\psi_{j,n} \eqdef \frac{1}{2^{j/2}} \psi\pa{ \frac{\cdot - 2^j n}{2^j} }.
}

Due to the orthogonal complementarity property, one has
\eq{
	L^2(\RR) = \bigoplus_{j=-\infty}^{j=+\infty} W_j
	= V_{j_0} \bigoplus_{j \leq j_0}^{j} V_j.
}
This means that for all $f \in L^2(\RR)$, one has the following convergence in $L^2(\RR)$, 
\eq{
	f = 
	\lim_{(j_-,j_+) \rightarrow (-\infty,+\infty)} \sum_{j=j_-}^{j_+} P_{V_j} f
	= 
	\lim_{j_+ \rightarrow +\infty} P_{j_0} f +  \sum_{j=j_0}^{j_+} P_{V_j} f. 
}
This decomposition shows that 
\eq{
	\enscond{\psi_{j,n}}{(j,n) \in \ZZ^2}
}
is an Hilbertian orthogonal basis of $L^2(\RR)$, which is called a wavelet basis.
%
One also have a ``truncated'' ortho-basis 
\eq{
	\enscond{\psi_{j,n}}{j \leq j_0, n \in \ZZ} \cup 
	\enscond{\phi_{j_0,n}}{n \in \ZZ}.
}

A (forward) Wavelet transform corresponds to the computation of all the inner products of some function $f$ with the elements of these basis.

\myfigure{
\tabdeux{
\image{wavelets}{.48}{multires-1d-haar-0}&
\image{wavelets}{.48}{multires-1d-haar-1}\\
Signal $f$ & $j=-8$ \\
\image{wavelets}{.48}{multires-1d-haar-2}&
\image{wavelets}{.48}{multires-1d-haar-3}\\
$j=-7$ & $j=-6$
}
}{%
	1-D Haar multiresolution projection $P_{V_j}f$ of a function $f$.%	
}{fig-haar-1d}



%%
\paragraph{Haar wavelets.}

For the Haar multiresolution~\eqref{eq-haar-multires}, one has
\eql{\label{eq-haar-details}
	W_j = \enscond{ f }{  \foralls n \in \ZZ, \; f \text{ constant on  } [2^{j+1} n, 2^{j+1} (n+1)) \qandq
	 \int_{n2^j}^{(n+1)2^j} f = 0 }.
}
A possible choice for a mother wavelet function is
\eq{
	\psi(t) = \frac{1}{\sqrt{2}} \choice{
		1 \qforq 0 \leq t < 1/2, \\
		-1 \qforq 1/2 \leq t < 1, \\
		0 \quad \text{otherwise,}
	}
}
as shown on Figure~\ref{fig-haard-scaling-wav}, right.


\myfigure{
\tabdeux{
\image{wavelets}{.48}{multires-1d-haar-1}& \\
$P_{V_{-7}} f$ & \\
\image{wavelets}{.48}{multires-1d-haar-2}&
\image{wavelets}{.48}{multires-1d-haar-detail-1}\\
$P_{V_{-6}}$ f & $P_{W_{-6}} f$ \\
\image{wavelets}{.48}{multires-1d-haar-3}&
\image{wavelets}{.48}{multires-1d-haar-detail-2} \\
$P_{V_{-5}} f$ & $P_{W_{-5}} f$
}
}{%
	Projection on Haar approximation spaces (left) and detail spaces (right).%	
}{fig-haar-appr-details}

Figure~\ref{fig-haar-appr-details} shows examples of projections on details spaces, and how they can be derived from projection on approximation spaces. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{On Bounded Domains}

On a periodic bounded domain $\TT=\RR/\ZZ$ (note that we use here 1-periodicity, in contrast to the convention we used for Fourier series of $2\pi$-periodicity), one obtains an orthogonal wavelet basis of $L^2(\TT)$ by periodizing the original wavelets, and also restricting the translation points $2^j n$ to be in $[0,1]$, i.e. $0 \leq n < 2^{-j}$. Similarly to~\eqref{eq-periodizing}, the periodization of a function $f \in L^1(\RR)$ is the function
\eq{
	f^P = \sum_{n \in \ZZ} f(\cdot-n) \in L^1(\TT). 
}
The wavelet basis is thus define as
\eq{
	\enscond{\psi_{j,n}^P}{j \leq j_0, 0 \leq n < 2^{-j}} \cup 
	\enscond{\phi_{j_0,n}^P}{0 \leq n < 2^{-j_0}}.
}
and one verifies that it defines an Hilbertian ortho-basis of $L^2(\TT)$.
%
It is possible to define wavelet basis using Neumann (mirror) boundary conditions, but this is more involved.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fast Wavelet Transform}

%%%
\subsection{Discretization}

We now work over $\RR/\ZZ$.
%
The modelling hypothesis is that one has acess to a discrete signal $a_J \in \RR^N$ with $N = 2^{-J}$ at some fixed scale $2^J$, and that this signal exactly matches the inner-product with the scaling functions, i.e.
\eql{\label{eq-hyp-wav-samples}
	\foralls n, \in \{0,\ldots,N-1\}, \quad a_{J,n} = \dotp{f}{\phi_{J,n}^P}
}
for some function of interest $f$ we are sampling. This is equivalent to saying that the discretization process have exactly access to $P_{V_J}f$. This hypothesis is questionnable, and similar to the Shannon bandlimit assumption. In practice, the scaling functions $\phi_{j,n}$ are often quite close to the point-spread function of the acquisition device, so it is acceptable. One can however improves this by correcting the acquired values by the device to be closer to asumption~\eqref{eq-hyp-wav-samples}.

The discrete wavelet transform then computes, from this input $a_J$, all the coefficients 
\eq{
	\foralls j \in \{J+1,J+2, \ldots, 0\}, \quad
	\foralls n \in \range{0,2^{-j}-1}, \quad
	a_{j,n} \eqdef \dotp{f}{\phi_{j,n}^P}, \qandq
	d_{j,n} \eqdef \dotp{f}{\psi_{j,n}^P}
}
in this order (increasing values of $j$). During the algorithm, the previously computed vector $a_j$ can be discarded, and only the $d_j$ are kept. 

The forward discrete wavelet transform on a bounded domain is thus the orthogonal finite dimensional map
\eq{
	a_J \in \RR^N \longmapsto
	\enscond{ d_{j,n} }{ 0 \leq j < J, 0 \leq n < 2^{-j} } \cup \{a_0 \in \RR\}. 
}
The inverse transform, which is thus the adjoint due to orthogonality, is the inverse map.


Figure~\ref{fig-wavcoef-1d} shows examples of wavelet coefficients. For each scale $2^j$, there are $2^{-j}$ coefficients.

\myfigure{
\tabun{
\image{wavelets}{.9}{wavcoef-1d-all}\\
Wavelet coefficients $\{d_{j,n}\}_{j,n}$
}
\tabdeux{
\image{wavelets}{.48}{wavcoef-1d-0}&
\image{wavelets}{.48}{wavcoef-1d-1}\\
Signal $f$ & $d_{-7}$ \\
\image{wavelets}{.48}{wavcoef-1d-2}&
\image{wavelets}{.48}{wavcoef-1d-3}\\
$d_{-6}$ & $d_{-5}$ 
}
}{%
	Wavelet coefficients. Top row: all the coefficients. Bottoms rows: zoom on the different scales%	
}{fig-wavcoef-1d}


%%%
\subsection{Forward Fast Wavelet Transform (FWT)}

The algorithm proceeds by computing a series of simple operators 
\eql{\label{eq-wavelet-step}
	\foralls j = J+1, \ldots, 0, \quad 
	(a_{j},d_{j}) = \Ww_j(a_{j-1})
	\qwhereq
	\Ww_j : \RR^{2^{-j+1}} \rightarrow \RR^{2^{-j}} \times \RR^{2^{-j}}
}
The number of such steps is thus $|J|=\log_2(N)$. Each $\Ww_j$ is orthogonal since it corresponds to linear maps between coefficients in orthogonal bases. 

In order to describe the algorihm that computes $\Ww_j$, we introduce the filters ``filter'' coefficients $f, g \in \RR^\ZZ$
\eql{\label{eq-dfn-h-g}
	h_n \eqdef \frac{1}{\sqrt{2}} \dotp{ \phi(\cdot/2) }{\phi(\cdot-n)}
	\qandq
	g_n \eqdef \frac{1}{\sqrt{2}} \dotp{ \psi(\cdot/2) }{\phi(\cdot-n)}.
}
We denote as $\downarrow_2 : \RR^K \rightarrow \RR^{K/2}$ the subsampling operator by a factor of 2, i.e.
\eq{
	u\downarrow_2 \eqdef (u_0,u_2,u_4,\ldots,u_{K-2},u_K).
}
In the following, we assume that these filters are decaying fast enough.

\begin{prop}
One has
\eql{\label{eq-convol-subsample}
	\Ww_j(a_j) = ( (\bar h \star a_{j-1})\downarrow_2, (\bar g \star a_{j-1})\downarrow_2 ), 
}
where $\star$ denotes periodic convolutions on $\RR^{-j+1}$. 
\end{prop}

\begin{proof}
We note that $\phi(\cdot/2)$ and $\psi(\cdot/2)$ are in $\Ww_j$, so one has the decompositions
\eql{\label{eq-phipsi-recurse-1}
	\frac{1}{\sqrt{2}} \phi(t/2) = \sum_n h_n \phi(t-n)
	\qandq
	\frac{1}{\sqrt{2}} \psi(t/2) = \sum_n g_n \phi(t-n)
}
Doing the change of variable $t \mapsto \frac{t-2^j p}{2^{j-1}}$ in~\eqref{eq-phipsi-recurse-1}, one obtains
\eq{
	\frac{1}{\sqrt{2}} \phi\pa{ \frac{t-2^j p}{2^j} }  = \sum_n h_n \phi\pa{ \frac{t}{2^{j-1}}-(n+2p)}
}
(similarly for $\psi$) and then doing the change $n \mapsto n-2p$, one obtains
\eq{
	\phi_{j,p} = \sum_{n \in \ZZ} h_{n-2p} \phi_{j-1,n}
	\qandq 
	\psi_{j,p} = \sum_{n \in \ZZ} g_{n-2p} \psi_{j-1,n}.
}
When working with periodized function $(\phi_{j,n}^P,\psi_{j,p}^P)$, this formula is still valid, but the summation over $n \in \ZZ$ should be done modulo $2^{-j+1}$. 
%
Taking inner product of both size with respect to $f$ (which is legit if $h,g$ are decaying fast enough), one obtains the fundamental recursion fromula
\eql{\label{eq-recurse-formula-wav}
	a_{j,p} = \sum_{n \in \ZZ} h_{n-2p} a_{j-1,n} = (\bar h \star a_{j-1})_{2p}
	\qandq 
	d_{j,p} = \sum_{n \in \ZZ} g_{n-2p} a_{j-1,n} = (\bar g \star a_{j-1})_{2p}
}
where $\bar u_n \eqdef u_{-n}$. 
%
One can show that this formula is still valid when working over a bounded interval $\TT=\RR/\ZZ$, but then $\star$ denotes the periodic convolution over $\ZZ/2^{-j+1}\ZZ$.
\end{proof}

Figure~\ref{fig-filterbank-fwd} shows two steps of application of these refinement relationships. 

\myfigure{
\image{wavelets}{.95}{filterbank-fwd}
}{%
	Forward filter bank decomposition.%	
}{fig-filterbank-fwd}

The FWT thus operates as follow:
\begin{rs}
	\item \textbf{Input:} signal $f \in \CC^N$.
	\item \textbf{Initialization:} $a_J = f$.
	\item \textbf{For} $j=J,\ldots,j_0-1$.
		\eq{
			a_{j+1} = (a_j \star \tilde h) \downarrow 2 \qandq
			d_{j+1} = (a_j \star \tilde g) \downarrow 2
		}
	\item \textbf{Output:} the coefficients $\{ d_j \}_{j_0 \leq j < J} \cup \{ a_{j_0} \}$.
\end{rs}

If $|h|,|g| \leq C$ so that both filter are compactly supported, then computing each $\Ww_j$ is $(2C) 2^{-j}$ operation, so that the complexity of the whole wavelet transform is 
\eq{
	\sum_{j=J}^1 (2C) 2^{-j} = (2C) 2^{-J} = 2CN. 
}
This shows that the fast wavelet transform is a linear time algorithm.
%
Figure~\ref{fig-filterbank-pyramidal} shows the process of extracting iteratively the wavelet coefficients.
%
Figure~\ref{fig-wavalgo-1d} shows an example of computation, where at each iteration, the coefficients of $a_j$ and $d_j$ are added to the left of the output vector.

\myfigure{
\image{wavelets}{.4}{filterbank-pyramidal}
}{%
	Pyramid computation of the coefficients. %	
}{fig-filterbank-pyramidal}

\myfigure{
\tabdeux{
\image{wavelets}{.48}{wavalgo-1d-0}&
\image{wavelets}{.48}{wavalgo-1d-1}\\
\image{wavelets}{.48}{wavalgo-1d-2}&
\image{wavelets}{.48}{wavalgo-1d-3}
}
}{%
	Wavelet decomposition algorithm.%	
}{fig-wavalgo-1d}


%%
\paragraph{Fast Haar transform.}

For the Haar wavelets, one has
\eq{
	\phi_{j,n} = \frac{1}{\sqrt{2}} ( \phi_{j-1,2n} + \phi_{j-1,2n+1} ),
}
\eq{
	\psi_{j,n} = \frac{1}{\sqrt{2}} ( \phi_{j-1,2n} - \phi_{j-1,2n+1} ).
}
This corresponds to the filters
\eq{
	h = [\ldots,\;0,\;h[0]=\frac{1}{\sqrt{2}},\;\frac{1}{\sqrt{2}},\;0,\ldots],
}
\eq{
	g = [\ldots,\;0,\;h[0]=\frac{1}{\sqrt{2}},\;-\frac{1}{\sqrt{2}},\;0,\ldots].
}
The Haar wavelet transform algorithm thus processes by iterating averaging and differences:
\begin{rs}
	\item \textbf{Input:} signal $f \in \CC^N$.
	\item \textbf{Initialization:} $a_J = f$.
	\item \textbf{For} $j=J,\ldots,j_0-1$.
		\eq{
			a_{j+1,n} = \frac{1}{\sqrt{2}} (a_{j-1,2n}+a_{j-1,2n+1}) \qandq
			d_{j+1,n} = \frac{1}{\sqrt{2}} (a_{j-1,2n}-a_{j-1,2n+1}).
		}
	\item \textbf{Output:} the coefficients $\{ d_j \}_{j_0 \leq j < J} \cup \{ a_{j_0} \}$.
\end{rs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Inverse Fast Transform (iFWT)}

The inverse algorithm proceeds by inverting each step~\eqref{eq-wavelet-step}
\eql{\label{eq-wavelet-step}
	\foralls j = 0, \ldots, J+1, \quad 
	a_{j-1} = \Ww_j^{-1}(a_{j},d_{j}), 
}
where $\Ww_j^{*}$ is the adjoint for the canonical inner product on $\RR^{2^{-j+1}}$ , i.e. when viewed as a matrix, the transpose.

We denote $\uparrow_2 : \RR^{K/2} \rightarrow \RR^K$ the up-sampling operator
\eq{
	a\uparrow_2 = (a_0,0,a_1,0,\ldots,0,a_{K/2},0) \in \RR^K.
}

\begin{prop}
One has
\eq{
	\Ww_j^{-1}(a_{j},d_{j}) = (a_{j}\uparrow_2) \star h +  (d_{j}\uparrow_2) \star g.
}
\end{prop}

\begin{proof}
Since $\Ww_j$ is orthogonal, $\Ww_j^{-1} = \Ww_j^*$.
%
We write the whole transform as 
\eq{
	\Ww_j = S_2 \circ C_{\bar h,\bar g} \circ \Dd
	\qwhereq
	\choice{
		\Dd(a)=(a,a), \\
		C_{\bar h,\bar g}(a,b) = (\bar h \star a, \bar g \star a), \\
		S_2( a,b ) = (a\downarrow_2, b\downarrow_2).	
	}
}
One has the following adjoint operator
\eq{
	\Dd^*(a,b)=a+b, \quad
	C_{\bar h,\bar g}^*(a,b) = (h \star a, g \star b), \qandq
	S_2( a,b ) = (a\uparrow_2, b\uparrow_2).
}
Indeed, let us check this for the convolution, assuming involved sequences are in $\ell_1$ (they are actually finite sums when considering periodic signals), 
\eq{
	\dotp{f \star \bar h}{g} = \sum_n (f \star \bar h)_n g_n = \sum_n \sum_k f_k h_{k-n} g_n
	 = 
	 \sum_k f_k  \sum_n h_{k-n} g_n = \dotp{f}{h \star g}, 
}
for the copying
\eq{
	\dotp{\Dd(a)}{(u,v)} = \dotp{a}{u} + \dotp{b}{u} = \dotp{a}{u+v} = \dotp{a}{\Dd^*(u,v)}, 
}
and for the down-sampling
\eq{
	\dotp{f\downarrow_2}{g} = \sum_{n} f_{2n}  g_{n} = \sum_{n} (f_{2n}  g_{n} + f_{2n+1} 0 )
	= \dotp{f}{g \uparrow_2}.  
}
This is shown using matrix notations in Figure~\ref{fig-inversion-transpose}.
%
Putting everything together gives the desired formula.
\end{proof}

\myfigure{
\image{wavelets}{.4}{inversion-transpose-1}
\raisebox{1.7cm}{$\qqarrqq$}
\image{wavelets}{.4}{inversion-transpose-2}
}{%
	Wavelet inversion in matrix format.%	
}{fig-inversion-transpose}


The inverse Fast wavelet transform iteratively applies this elementary step
\begin{rs}
	\item \textbf{Input:} $\{ d_j \}_{j_0 \leq j < J} \cup \{ a_{j_0} \}$.
	\item \textbf{For} $j=j_0, \ldots, J+1$.
		\eq{
			a_{j-1} = (a_j \uparrow 2) \star h +  (d_j \uparrow 2) \star g.
		}
	\item \textbf{Output:} $f = a_J$.
\end{rs}
This process is shown using a block diagram in Figure~\ref{fig-filterbank-bwd}, which is the inverse of the block diagram~\ref{fig-filterbank-fwd}. 

\myfigure{
\image{wavelets}{.95}{filterbank-bwd}
}{%
	Backward filterbank recomposition algorithm.%	
}{fig-filterbank-bwd}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{2-D Wavelets}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Anisotropic Wavelets}

2-D anisotropic wavelets are defined using tensor product of Wavelet basis functions~\eqref{eq-tensor-product}. The basis over $\TT^2$ is thus of the form
\eq{
	\enscond{ \psi_{(j_1,j_2),(n_1,n_2)} }{ (j_1,j_2) \in \ZZ^2, 0 \leq n_1 < 2^{-j_1}, 0 \leq n_2 < 2^{-j_2} }
}
\eql{\label{eq-aniso-wav}
	\qwhereq
	\psi_{(j_1,j_2),(n_1,n_2)}(x_1,x_2) = \psi_{j_1,n_1}(x_1)\psi_{j_2,n_2}(x_2). 
}
The computation of the fast anisotropic Wavelet transform in 2-D is similar to the 2-D FFT detailed in Section~\ref{sec-fft-2d}. Viewing the input image $a_J \in \RR^{2^{-J} \times 2^{-J}}$ as a matrix, one first apply the 1-D FWT to each row, and then to each column, resulting in a linear time $O(N)$ algorithm, where $N=2^{-2J}$. 

\myfigure{
\tabtrois{
\image{wavelets}{.3}{wavalgo-2d-aniso-0}&
\image{wavelets}{.3}{wavalgo-2d-aniso-1}&
\image{wavelets}{.36}{wavalgo-2d-aniso-2}\\
Image $f$ & Row transform & Column transform.
}
}{%
	Steps of the anisotropic wavelet transform.%	
}{fig-wavalgo-2d-aniso}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Isotropic Wavelets}

A major issue with these anisotropic wavelet~\eqref{eq-aniso-wav} is that a function $\psi_{(j_1,j_2),(n_1,n_2)}$ is scaled independently in each direction, leads to functions concentrated along an axis-oriented rectangle of size $2^{-j_1} \times 2^{j_2}$. This is not a very good features (since natural images usually do not exhibit such an anisotropy) and typically leads to visually unpleasant artifacts when used for processing (denoising or compression). 

\myfigure{
\image{wavelets}{.3}{wavcoefs-iso-aniso-2}
\image{wavelets}{.3}{wavecoefs-iso-aniso-1}
}{%
	Anisotropic (left) versus isotropic (right) wavelet coefficients.%	
}{fig-wavecoefs-iso}

One rather use isotropic wavelet obtained by considering 2-D multi-resolution, obtained by tensor products of the 1-D approximation spaces
\eq{
	L^2(\RR^2) \supset \ldots \supset V^{j-1} \otimes V^{j-1} \supset V_j \otimes V_j \supset V_{j+1} \otimes V_{j+1} \supset \ldots \supset \{0\}.
}
In the following, we denote 
\eq{
	V_j^O \eqdef V_j \otimes V_j
} 
this isotropic 2-D multiresolution space. 

Recall that the tensor product of two space $(V_1,V_2) \in L^2(\RR)^2$ is
\eq{
	V_1 \otimes V_2 = \text{Closure}\pa{ \Span\enscond{f_1(x_1)f_2(x_2) \in L^2(\RR^2)}{ f_1 \in V_1, f_2 \in V_2 } }.
}
If $(\phi_k^s)_k$ are Hilbertian bases for $V_s$, then one can show that $( \phi_k^1(x_1)\phi_k^2(x_2) )_{k}$ is an Hilbertian basis for $V_1 \otimes V_2$.

One easily verify that one has the distributivity
\eq{
		( V_j \oplus^\bot W_J) \otimes ( V_j \oplus^\bot W_J)
		= 
		V_j^O \oplus^\bot W_j^V \oplus^\bot W_j^V \oplus^\bot W_j^V
		\qwhereq
		\choice{
		W_j^V \eqdef (V_j \otimes W_j), \\
		W_j^H \eqdef (W_j \otimes V_j),  \\
		W_j^D \eqdef (W_j \otimes W_j).
		}
}
Here the letters $\{V,H,D\}$ stands for \textit{Vertical, Horizontal, Diagonal} detail spaces. 
%
This leads to the following diagram of embedded spaces
\begin{center}
	\image{wavelets}{.8}{embeded-spaces-2d}
\end{center}

For $j \in \ZZ$, each of the three wavelet spaces is spanned with a wavelet, where basis elements are indexed by $n=(n_1,n_2) \in \ZZ$ (or in $\{0,\ldots,2^{-j}-1\}^2$ on the interval $\TT$),
\eq{
	\foralls \om \in \{V,H,D\}, \quad
	W_j^\om = 
	\text{Span}\{ \psi_{j,n_1,n_2}^\om \}_{n_1,n_2}
}
where
\eq{
	\foralls \om \in \{V,H,D\}, \quad
	\psi_{j,n_1,n_2}^{\om}(x) = \frac{1}{2^j}\psi^\om\pa{ \frac{x_1-2^j n_1}{2^j}, \frac{x_2-2^j n_2}{2^j} }
}
and where the three mother wavelets are
\eq{
	\psi^H(x)=\psi(x_1)\phi(x_2),\quad
	\psi^V(x)=\phi(x_1)\psi(x_2), \qandq
	\psi^D(x)=\psi(x_1)\psi(x_2).
}
Figure~\ref{fig-wavelets-2d} displays an examples of these wavelets.

\myfigure{
\tabquatre{
\image{wavelets}{.24}{wavelets-2d-1}&
\image{wavelets}{.24}{wavelets-2d-2}&
\image{wavelets}{.24}{wavelets-2d-3}&
\image{wavelets}{.24}{wavelets-2d-support}\\
$\psi^H$ & $\psi^V$ & $\psi^D$ & Support
}
}{%
	2-D wavelets and their approximative support (right).%	
}{fig-wavelets-2d}


%%
\paragraph{Haar 2-D multiresolution.}

For the Haar multiresolution, one obtains 2-D piecewise-constant Haar approximation. A function of $V_j \otimes V_j$ is constant on squares of size $2^j \times 2^j$. Figure~\ref{fig-multires-2d-haar} shows an example of projection of an image onto these 2-D Haar approximation spaces. 

\myfigure{
\image{wavelets}{.24}{multires-2d-haar-0}
\image{wavelets}{.24}{multires-2d-haar-1}
\image{wavelets}{.24}{multires-2d-haar-2}
\image{wavelets}{.24}{multires-2d-haar-3}
}{%
	2-D Haar approximation $P_{V_j^O}f$ for increasing $j$.%	
}{fig-multires-2d-haar}

%%
\paragraph{Discrete 2-D wavelet coefficients.}

Similarly to~\eqref{eq-hyp-wav-samples}, we suppose that the sampling mechanism gives us access to inner product of the analog (continuous) signal $f$ with the scaling function at scale $N=2^{-J}$
\eq{
	\foralls n, \in \{0,\ldots,N-1\}^2, \quad a_{J,n} = \dotp{f}{\phi_{J,n}^P}
}
Discrete wavelet coefficients are defined as
\eq{
	\foralls \om \in \{V,H,D\}, \; \foralls J < j \leq 0, \; \foralls 0 \leq n_1,n_2 < 2^{-j}, \quad
	d_{j,n}^\om = \dotp{ f }{ \psi_{j,n}^{\om} } .
}
(we use here periodized wavelets).
%
Approximation coefficients are defined as
\eq{
	a_{j,n} = \dotp{f_0}{\phi_{j,n}^O}.
}

\myfigure{
\image{wavelets}{.3}{wavcoefs-2d-original}
\image{wavelets}{.42}{wavcoefs-2d-coefs}
}{%
	2-D wavelet coefficients.%	
}{fig-wavcoefs-2d}

Figure~\ref{fig-wavcoefs-2d} shows examples of wavelet coefficients, that are packed in an image of $N$ pixels.
%
Figure~\ref{fig-wavcoefs-example} shows other examples of wavelet decompositions.

\myfigure{
\tabtrois{
\image{wavelets}{.3}{wavcoefs-example-square}&
\image{wavelets}{.3}{wavcoefs-example-boat}&
\image{wavelets}{.3}{wavcoefs-example-mandrill}\\
\image{wavelets}{.3}{wavcoefs-example-square-coefs}&
\image{wavelets}{.3}{wavcoefs-example-boat-coefs}&
\image{wavelets}{.3}{wavcoefs-example-mandrill-coefs}
}
}{%
	Examples of images (top row) and the corresponding wavelet coefficients (bottom row) .%	
}{fig-wavcoefs-example}

%%
\paragraph{Forward 2-D wavelet transform basic step.}

A basic step of the computation of the 2-D wavelet transform computes detail coefficients and a low pass residual from the fine scale coefficients
\eq{
	a_{j-1} \longmapsto (a_j, d_j^H, d_j^V, d_j^D).
}
Similarly to the 1-D setting, this mapping is orthogonal, and is computed using the 1-D filtering and sub-sampling formula~\eqref{eq-convol-subsample}.

One first applies 1-D horizontal filtering and sub-sampling
\eqm{
	\tilde a_j &= ( a_{j-1} \star^H \tilde h ) \downarrow^H 2\\
	\tilde d_j &= ( a_{j-1} \star^H \tilde h ) \downarrow^H 2,
}
where $\star^H$ is the horizontal convolution, that applies the 1-D convolution to each column of a matrix
\eq{
	a \star^H b_{n_1,n_2} = \sum_{m_1=0}^{P-1} a_{n_1-m_1,n_2} b_{m_1}
}
where $a \in \CC^{P \times P}$ and $b \in \CC^P$ are matrix and vectors. The notation $\downarrow^H 2$ accounts for sub-sampling in the horizontal direction
\eq{
	(a \downarrow^H 2)_{n_1,n_2} = a_{2n_1,n_2}.
}

One then applies 1-D vertical filtering and sub-sampling to $\tilde a_j$ and $\tilde d_j$ to obtain
\eqm{
	\begin{array}{ll}
	a_j &=  ( \tilde a_j \star^V \tilde h ) \downarrow^V 2,\\
	d_j^V &= ( \tilde a_j \star^V \tilde g ) \downarrow^V 2,
	\end{array}\qquad	
	\begin{array}{ll}
	d_j^H &= ( \tilde d_j \star^V \tilde h ) \downarrow^V 2,\\
	d_j^D &= ( \tilde d_j \star^V \tilde g ) \downarrow^V 2,
	\end{array}
}
where the vertical operators are defined similarly to horizontal operators but operating on rows.

\myfigure{
\image{wavelets}{.9}{wavalgo-2d-step-fwd}
}{%
	Forward 2-D filterbank step.%	
}{fig-wavalgo-2d-step-fwd}

\myfigure{
\tabtrois{
\image{wavelets}{.24}{wavalgo-2d-0}&
\image{wavelets}{.24}{wavalgo-2d-1}&
\image{wavelets}{.24}{wavalgo-2d-2}\\
Coefficients $a_j$ & Transform on rows & Transform on columns
}
}{%
	One step of the 2-D wavelet transform algorithm.%	
}{fig-wavalgo-2d}

These two forward steps are shown in block diagram in Figure~\ref{fig-wavalgo-2d-step-fwd}. 
These steps can be applied in place, so that the coefficients are stored in an image of $N$ pixels, as shown in Figure~\ref{fig-wavalgo-2d}. This gives the traditional display of wavelet coefficients used in Figure~\ref{fig-wavcoefs-example}.

%%
\paragraph{Fast 2-D wavelet transform.}

The 2-D FWT algorithm iterates these steps through the scales:
\begin{rs}
	\item \textbf{Input:} signal $f \in \CC^N$.
	\item \textbf{Initialization:} $a_J = f$.
	\item \textbf{For} $j=J,\ldots,j_0-1$.
		\eq{
			\begin{array}{ll}
			\tilde a_j &= ( a_{j-1} \star^H \tilde h ) \downarrow^H 2, \\ 
			\tilde d_j &= ( a_{j-1} \star^H \tilde h ) \downarrow^H 2, \\
			a_j &=  ( \tilde a_j \star^V \tilde h ) \downarrow^V 2, 
			\end{array}\qquad			
			\begin{array}{ll}
			d_j^V &= ( \tilde a_j \star^V \tilde g ) \downarrow^V 2,\\
			d_j^H &= ( \tilde d_j \star^V \tilde h ) \downarrow^V 2,\\
			d_j^D &= ( \tilde d_j \star^V \tilde g ) \downarrow^V 2.
			\end{array}
		}
	\item \textbf{Output:} the coefficients $\{ d_j^\om \}_{j_0 \leq j < J, \om} \cup \{ a_{j_0} \}$.
\end{rs}


%%
\paragraph{Fast 2-D inverse wavelet transform.}

The inverse transform undo the horizontal and vertical filtering steps. 
The first step computes
\eqm{
	\tilde a_j &= (a_j \star^V h) \uparrow^V 2 + (d_j^V \star^V g) \uparrow^V 2,\\
	\tilde d_j &= (d_j^H \star^V h) \uparrow^V 2 + (d_j^D \star^V g) \uparrow^V 2,
}
where the vertical up-sampling is
\eq{
	(a \uparrow^V 2)_{n_1,n_2} = 
	\choice{
		a_{k,n_2} \qifq n_1=2k, \\
		0 \qifq n=2k+1.
	}
}
The second inverse step computes
\eqm{
	a_{j-1} &= (\tilde a_j \star^H h) \uparrow^H 2 + (\tilde d_j \star^H g) \uparrow^H 2.
}
Figure~\ref{fig-wavalgo-2d-step-bwd} shows in block diagram this inverse filter banks, that is the inverse of the diagram~\ref{fig-wavalgo-2d-step-fwd}.

\myfigure{
\image{wavelets}{.9}{wavalgo-2d-step-bwd}
}{%
	Backward 2-D filterbank step.%	
}{fig-wavalgo-2d-step-bwd}

The inverse Fast wavelet transform iteratively applies these elementary steps
\begin{rs}
	\item \textbf{Input:} $\{ d_j^\om \}_{j_0 \leq j < J, \om} \cup \{ a_{j_0} \}$.
	\item \textbf{For} $j=j_0, \ldots, J+1$.
		\eqm{
			\tilde a_j &= (a_j \star^V h) \uparrow^V 2 + (d_j^V \star^V g) \uparrow^V 2,\\
			\tilde d_j &= (d_j^H \star^V h) \uparrow^V 2 + (d_j^D \star^V g) \uparrow^V 2,\\
			a_{j-1} &= (\tilde a_j \star^H h) \uparrow^V 2 + (\tilde d_j \star^H g) \uparrow^V 2.
		}
	\item \textbf{Output:} $f = a_J$.
\end{rs}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Wavelet Design}

To be able to compute the wavelet coefficients using the FWT algorithm, it remains to know how to compute the scaling and wavelet functions. The FWT only makes use of the filters $h$ and $g$, so instead of explicitly knowing the functions $\phi$ and $\psi$, one can only know these filters. Indeed, most of the known wavelets do not have explicit formula, and are implicitly defined through the cascade of the FWT algorithm. 

This section shows what are the constraints $h$ and $g$ should satisfy, and gives practical examples. Furthermore, it shows that the knowledge of $h$ determines $g$ under the constraint of having quadrature filters, which is the most usual choice for wavelet analysis.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Low-pass Filter Constraints}

We introduce the following three conditions on a filter $h$
\begin{align}
	\label{eq-cond-h-1}\tag{$C_1$}  \hat h(0)&=\sqrt{2}  \\
	\label{eq-cond-h-2}\tag{$C_2$}   |\hat h(\om)|^2 + |\hat h(\om+\pi)|^2&=2, \\
	\label{eq-cond-h-star}\tag{$C^*$}  \underset{\om \in [-\pi/2,\pi/2]}{\inf} |\hat h(\om)|&>0.
\end{align}

Here we are using the Fourier series associated to a filter $h \in \RR^\ZZ$
\eq{\label{eq-fourier-tr-infi}
	\forall \om \in \RR/2\pi\ZZ, \quad
	\hat h(\om) \eqdef \sum_{n \in \ZZ} h_n e^{-\imath n \om }.
}
If $h \in \ell^1(\ZZ)$, this defines a continuous periodic fonction $\hat h \in \Cc^0(\RR/2\pi\ZZ)$, and this definition can be extended to $h \in \ell^2(\ZZ)$ and defines $\hat h \in L^2(\RR/2\pi\ZZ)$.

\begin{thm}\label{thm-multires-approx}
	If $\phi$ defines multi-resolution approximation spaces, then~\eqref{eq-cond-h-1} and~\eqref{eq-cond-h-2} holds for $h$ defined in~\eqref{eq-dfn-h-g}.
	%
	Conversely, if~\eqref{eq-cond-h-1},~\eqref{eq-cond-h-2} and~\eqref{eq-cond-h-star} holds, then there exists a $\phi$ defining multi-resolution approximation spaces so that associated filter is $h$ as defined in~\eqref{eq-dfn-h-g}.
\end{thm}

\begin{proof} We only prove the first statement of the theorem. The converse statement is much more difficult to prove.

%%
We now prove condition~\eqref{eq-cond-h-1}.
%
The refinement equation reads like a discrete-continuous convolution (or equivalently a convolution with a distribution)
\eql{\label{eq-wav-proof-refine}
	\frac{1}{\sqrt{2}} \phi\pa{\frac{t}{2}} = \sum_{n \in \ZZ} h_n \phi(t-n).
}
%
Denoting $h \star \phi$ such a convolution, assuming $h \in \ell_1(\ZZ)$ and $\phi \in L^1(\RR)$, one check that one can apply Fubini and that $h \star \phi \in L^1(\RR)$ and then 
\begin{align*}
	\Ff( \sum_{n \in \ZZ} h_n \phi(t-n) )(\om) &= \int_\RR \sum_{n \in \ZZ} h_n \phi(t-n) e^{-\imath \om t} \d t
	= \sum_{n \in \ZZ} h_n \int_\RR \phi(t-n) e^{-\imath \om t} \d t \\
	& = \sum_{n \in \ZZ} h_n e^{-\imath n \om } \int_\RR \phi(x) e^{-\imath \om x} \d x
	= \hat \phi(\om) \hat h(\om)
\end{align*}
where we made the change of variable $x = t-n$. Note that here, $h(\om)$ is the $2\pi$-periodic Fourier transform (i.e. Fourier series) of infinite filters defined in~\eqref{eq-fourier-tr-infi}, whereas $\hat\phi(\om)$ is the Fourier transform of function. This is thus a product of a $2\pi$-periodic function $\hat h$ and a non-periodic function $\hat \phi$. 
%
We recall that $\Ff(f(\cdot/s)) = s \hat f(s \cdot)$.
%
Over the Fourier domain, equation~\eqref{eq-wav-proof-refine} thus reads
\eql{\label{eq-wav-proof-refine-fourier}
	\hat\phi(2\om) = \frac{1}{\sqrt{2}}\hat h(\om) \hat \phi(\om).
}
One can show that $\hat \phi(0) \neq 0$ (actually, $|\hat \phi(0)| = 1$), so that this relation implies the first condition~\eqref{eq-cond-h-1}.


%%
We now prove condition~\eqref{eq-cond-h-2}.
%
The orthogonality of $\phi(\cdot-n) \}_n$ is rewritten using a continuous convolution as (see also  Proposition~\ref{prop-spectral-ortho})
\eq{
	\foralls n \in \ZZ, \quad \phi \star \bar \phi(n)=\de_0
}
where $\bar \phi(x) = \phi(-x)$, 
and thus over the Fourier domain, using~\eqref{eq-wav-proof-refine-fourier} which shows $\hat\phi\om) = \frac{1}{\sqrt{2}}\hat h(\om/2) \hat \phi(\om/2)$
\eq{
	1 = \sum_k |\hat \phi(\om+2k\pi)|^2 = \frac{1}{2}\sum_k |\hat h(\om/2+k\pi)|^2 |\hat \phi(\om/2+k\pi)|^2.
}
Since $\hat h$ is $2\pi$-periodic, one can split even and odd $k$ and obtain
\eq{
	2 = |h(\om/2)|^2 \sum_k |\hat \phi(\om/2+2k\pi)|^2 +
	    |h(\om/2+\pi)|^2 \sum_k |\hat \phi(\om/2+2k\pi+\pi)|^2
}
This leads to condition~\eqref{eq-cond-h-2}. Re-using the fact that $\sum_k |\hat \phi(\om+2k\pi)|^2=1$ for $\om'=\om/2$ in place of $\om$, one thus has 
\eq{
	|h(\om')|^2+|h(\om'+\pi)|^2 = 2.
}

%%
We do not prove the converse statement, which requires to ``create'' a function $\phi$ from the filter $h$. The intuition is that iterating~\eqref{eq-wav-proof-refine-fourier} leads informally to
\eql{\label{eq-dfn-cascade-inf}
	\phi(\om) = \prod_{k < 0} \frac{\hat h(\om/2^k)}{\sqrt{2}}.
}
Condition~\eqref{eq-cond-h-star} can be shown to imply that this infinite product converge, and define a (non-periodic) function in $L^2(\RR)$.
\end{proof}


Note that for the converse statement of this theorem to holds, condition~\eqref{eq-cond-h-star} imposes a control on the behavior of $\hat h$ near 0. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{High-pass Filter Constraints}

We now introduce the following two conditions on a pair of filter $(g,h)$
\begin{align}
	\label{eq-cond-g-1}\tag{$C_3$}  |\hat g(\om)|^2 + |\hat g(\om+\pi)|^2&=2  \\
	\label{eq-cond-g-2}\tag{$C_4$}   \hat g(\om) \hat h(\om)^* + \hat g(\om+\pi) \hat h(\om+\pi)^*&=0.
\end{align}


\begin{thm}\label{thm-wave-h}
	If $(\phi,\psi)$ defines a multi-resolution analysis, then~\eqref{eq-cond-g-1} and~\eqref{eq-cond-g-2} holds for $(h,g)$ defined in~\eqref{eq-dfn-h-g}.
	%
	Conversely, if~\eqref{eq-cond-h-1} to~\eqref{eq-cond-g-2} hold, then there exists a $(\phi,\psi)$ defining multi-resolution analysis so that associated filters are $(h,g)$ as defined in~\eqref{eq-dfn-h-g}. Furthermore, 
	\eql{\label{eq-rel-psi-phi}
		\hat \psi(\om) = \frac{1}{\sqrt{2}} \hat g(\om/2) \hat \phi(\om/2).
	}
\end{thm}

\begin{proof}
We prove condition~\eqref{eq-cond-g-1}.
%
The refinement equation for the wavelet reads
\eq{
	\frac{1}{\sqrt{2}} \psi\pa{\frac{t}{2}} = \sum_{n \in \ZZ} g_n \phi(t-n)
}
and thus over the Fourier domain
\eql{\label{eq-ref-fourier-wav}
	\hat\psi(2\om) = \frac{1}{\sqrt{2}}\hat g(\om) \hat \phi(\om).
}
The orthogonality of $\{ \psi(\cdot-n) \}_n$ is re-written
\eq{
	\foralls n \in \ZZ, \quad  \psi \star \bar \psi(n)=\de_0
}
and thus over the Fourier domain (using Poisson formula, see also Proposition~\ref{prop-spectral-ortho})
\eq{
	\sum_k |\hat \psi(\om+2k\pi)|^2 = 1.
}
Using the Fourier domain refinement equation~\eqref{eq-ref-fourier-wav}, similarely to the proof of Theorem~\ref{thm-multires-approx} for~\eqref{eq-cond-h-1}, this is equivalent to condition~\eqref{eq-cond-g-1}.
%
Figure~\ref{fig-filters-complements} shows the Fourier transform of two filters that satisfy this complementary condition.

\myfigure{
\image{wavelets}{.4}{filters-complement}
}{%
	Complementarity between a low pass and a high pass wavelet filters $h$ and $g$ that satisfy condition~\eqref{eq-cond-g-1}.%	
}{fig-filters-complements}

We now prove condition~\eqref{eq-cond-g-2}.
%
The orthogonality between $\{ \psi(\cdot-n) \}_n$ and $\{ \phi(\cdot-n) \}_n$ is written as
\eq{
	\foralls n \in \ZZ, \quad \psi \star \bar \phi(n)=0
}
and hence over the Fourier domain (using Poisson formula, similarly to Proposition~\ref{prop-spectral-ortho})
\eq{
	\sum_k \hat \psi(\om+2k\pi)\hat \phi^*(\om+2k\pi) = 0.
}
Using the Fourier domain refinement equations~\eqref{eq-wav-proof-refine-fourier} and~\eqref{eq-ref-fourier-wav}, this is equivalent to condition~\eqref{eq-cond-g-2}.
\end{proof}


%%
\paragraph{Quadrature mirror filters.}

Quadrature mirror filters (QMF) defines $g$ as a function of $h$ so that the conditions of Theorem~\ref{thm-wave-h} are automatically satisfy. This choice is the natural choice to build wavelet filters, and is implicitly assumed in most constructions (other choices leading to the same wavelet function anyway, since it safisfies~\eqref{eq-rel-psi-phi}).

\begin{prop}
	For a filter $h \in \ell^2(\ZZ)$ satisfying~\eqref{eq-cond-h-1}, defining $g \in \ell^2(\ZZ)$ as
	\eql{\label{eq-qmf}
		\foralls n \in \ZZ, \quad g_n = (-1)^{1-n}h_{1-n}
	}
	satisfies conditions~\eqref{eq-cond-g-1} and~\eqref{eq-cond-g-2}.
\end{prop}

\begin{proof}
	One indeed has that 
	\eql{\label{eq-qmf}
		\hat g(\om) = e^{-i \om} \hat h(\om+\pi)^*, 
	}
	so that 
	\eq{
		|\hat g(\om)|^2 + |\hat g(\om+\pi)|^2 = 
		|e^{-i \om} \hat h(\om+\pi)^*|^2 + |e^{-i (\om+\pi)} \hat h(\om+2\pi)^*|^2
		= 
		|\hat h(\om+\pi)|^2 + |\hat h(\om+2\pi)|^2 = 2.
	}
	where we used the fact that $\hat h$ is $2\pi$-periodic, 
	and also 
	\begin{align*}
		\hat g(\om) \hat h(\om)^* + \hat g(\om+\pi) \hat h(\om+\pi)^* &= 
		e^{-i \om} \hat h(\om+\pi)^* \hat h(\om)^* + e^{-i (\om+\pi)} \hat h(\om+2\pi)^* \hat h(\om+\pi)^* \\
		&=
		(e^{-i \om}+e^{-i (\om+\pi)}) \hat h(\om+\pi)^* \hat h(\om)^*
		=0.
	\end{align*}
\end{proof}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Wavelet Design Constraints}

According to the previous sections, the construction of a multi-resolution analysis (i.e. of functions $(\phi,\psi$) is obtained by designing a filter $h$ satisfying conditions~\eqref{eq-cond-h-1} and~\eqref{eq-cond-h-2}. The function $\phi$ is obtained by an infinite cascade of filtering, or equivalently in the Fourier domain by~\eqref{eq-dfn-cascade-inf}, there is in general (put aside special case such as the Haar multiresolution) no closed form expression for $\phi$. Once $\phi$ is defined, $\psi$ is automatically defined by the relation~\eqref{eq-rel-psi-phi} (and $g$ can be defined as~\eqref{eq-qmf}). 

There exists only one Fourier transform, but there is a large choice of different mother wavelet functions $\psi$. They are characterized by
\begin{rs}
	\item Size of the support.
	\item Number of oscillations (the so called number $p$ of vanishing moments).
	\item Symmetry (only possible for non-orthogonal bases).
	\item Smoothness (number of derivatives).
\end{rs}
We now detail how these constraints are integrated together with conditions ~\eqref{eq-cond-h-1}-~\eqref{eq-cond-g-2}.

%%
\paragraph{Vanishing moments.}

A wavelet $\psi$ has $p$ vanishing moments if
\eql{\label{eq-dfn-vm}
	\foralls k \leq p-1, \quad \int_\RR \psi(x) \, x^k \d x = 0.
}
This ensures that $\dotp{f}{\psi_{j,n}}$ is small if $f$ is $\Cal$, $\al<p$ on Supp$(\psi_{j,n})$.

This condition can be equivalently expressed over Fourier as
\eq{
	\foralls k \leq p-1, \quad 
	\frac{\d^k \hat h}{\d \om^k}(\pi) = \frac{\d^k \hat g}{\d \om^k}(0) = 0.
}

%%
\paragraph{Support.}

Figure~\ref{fig-vanishing-moments-1d} shows the wavelet coefficients of a piecewise smooth signal. Coefficients of large magnitude are clustered near the singularities, because the wavelet $\psi$ has enough vanishing moments.

\myfigure{
\image{wavelets}{.6}{vanishing-moments-1d-coefs}
}{%
	Location of large wavelet coefficients.%	
}{fig-vanishing-moments-1d}

To avoid that many wavelets create large coefficients near singularities, one should choose $\psi$ with a small support.
This requirement is however contradictory with the vanishing moment property~\eqref{eq-dfn-vm}. Indeed, one can prove that 
for an orthogonal wavelet basis with $p$ vanishing moments
\eq{
	|\text{Supp}(\psi)| \geq 2p-1,
} 
where $\sup(a)$ is the largest closed interval outside of which the function $f$ is zero.

%%
\paragraph{Smoothness.}

In compression or denoising applications, an approximate signals is recovered from a partial set $I_M$ of coefficients, 
\eq{
	f_M = \sum_{(j,n) \in I_M} \dotp{f}{\psi_{j,n}} \psi_{j,n}.
}
This approximation $f_M$ has the same smoothness as $\psi$. 

To avoid visually unpleasant artifacts, one should thus choose a smooth wavelet function $\psi$. This is only for cosmetic reasons, since increasing smoothness does not leads to a better approximation. However, for most wavelet family, increasing the number of vanishing moments also increases the smoothness of the wavelets. This is for instance the case of the Daubechies family exposed in the next section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Daubechies Wavelets}

To build a wavelet $\psi$ with a fixed number $p$ of vanishing moments, one designs the filter $h$, and use the quadrature mirror filter relation~\eqref{eq-qmf} to compute $g$. One thus look for $h$ such that 
\eq{
	|\hat h(\om)|^2 + |\hat h(\om+\pi)|^2 = 2, \quad 
	\hat h(0)=\sqrt{2}, \qandq
	\foralls k <p, \; {\frac{\d^k \hat h}{\d \om^k} }(\pi)=0.
}
This corresponds to algebraic relationships between the coefficients of $h$, and it turns out that they can be solved explicitly using the Euclidean division algorithm for polynomials.  

This leads to Daubechies wavelets with $p$ vanishing moments, which are orthogonal wavelets with a minimum support length of $2p-1$.

For $p=1$, it leads to the Haar wavelet, with 
\eq{
	h= [h_0 = 0.7071;    0.7071].
}
For $p=2$, one obtains the celebrated Daubechies 4 filter 
\eq{
	h = [0.4830 ;  h_0=0.8365  ;  0.2241  ; -0.1294],
}
and for $p=3$,
\eq{
	h =  [0  ;  0.3327  ;  0.8069  ;  h_0=0.4599; -0.1350 ;-0.0854   ; 0.0352].
}

%%
\paragraph{Wavelet display.}

Figure~\ref{fig-wavelets} shows examples of Daubechies mother wavelet functions with an increasing number of vanishing moments. These displays are obtained by computing in fact a discrete wavelet $\bar \psi_{j,n}$ defined in~\eqref{eq-discr-wav-basis} for a very large number of samples $N$. This discrete wavelet is computed by applying the inverse wavelet transform to the coefficients
$d_{j',n'} = \delta_{j-j'} \delta_{n-n'}$.

\myfigure{
\tabdeux{
\image{wavelets}{.45}{wavelet-daubechies-1}
\image{wavelets}{.45}{wavelet-daubechies-2}\\
\image{wavelets}{.45}{wavelet-daubechies-3}
\image{wavelets}{.45}{wavelet-daubechies-4}
}
}{%
	Examples of Daubechies mother wavelets $\psi$ with an increasing number $p$ of vanishing moments. %	
}{fig-wavelets}


